Hardware-Accelerated Rendering
### GPU Pipeline
- Main job is to make raster images
- Scene Data in CPU Memory => GPU Memory => GPU => Raster Image => Display (usually)
	- Assume scene data is a collection of triangles for now
### GPU
Takes scene data and does
- Transformations => Rasterization => Coloring
- Transformations (Vertex Shader)
	- Transformations into Canonical View Volume
	- Looks at one vertex (of each triangle) at a time, and transforms it into Canonical View Space
	- Additional shaders can take place after the Vertex Shader and before Rasterization
- Rasterization (Rasterizer)
	- Converts scene data (triangles) into Raster image pixels
- Coloring (Fragment Shader)
	- Compute color of each pixel
- Vertex Shader and Fragment Shader are programmable (Rasterizer is hardware)
- Rasterizer expects a certain input from Vertex Shader and gives a certain type of output to Fragment Shader 
- GPU is controlled by a CPU application (CPU code defines what the GPU code will do, they are not the same)
	- CPU sets code and parameters (uniform variables (applied to entire scene)) used by Vertex and Fragment Shaders on GPU
	- This code is often not precompiled, the GPU compiles it itself as it runs
	- Done through Graphics API
### WebGL
JavaScript Graphics API
- Initialization
```HTML
<canvas id="mycanvas"></canvas>
```

```JS
// onload function runs after webpage is loaded, needed so we can get the canvas after it is created
window.onload = function()
{
	canvas = document.getElementById("mycanvas");
	gl = canvas.getContext("webgl"); // class (called a context) that has functions to use GPU, context means there is a corresponding component on the GPU as well

	// adjust output image resolution
	const pixelRatio = window.devicePixelRatio || 1; // gets ratio of size of display in pixels to actual number of pixels
	canvas.width  = pixelRatio * canvas.clientWidth;
	canvas.height = pixelRatio * canvas.clientHeight;
	// set viewport size to the same as canvas
	gl.viewport(0, 0, canvas.width, canvas.height);

	gl.clearColor(1, 1, 1, 0); // sets color to clear screen with (white, 0 alpha)
	gl.lineWidth(1.0); // sets width of lines drawn with webGL (1.0 is max)
}
```

Scene Data and WebGL Primitives
- GL_POINTS, GL_LINES, GL_LINE_STRIP, GL_LINE_LOOP, GL_TRIANGLES, GL_TRIANGLE_STRIP, GL_TRIANGLE_FAN
- All defined by a list of vertices
	- Vertex positions
	- Vertex colors
	- Vertex ...
	- Data container basically
	- These properties are called Vertex Attributes
	- Ex.) Positions would be xyzxyzxyzxyzxyzxyzxyz...
```JS
var positions = [
	-0.8, 0.4, 0,
	0.8, 0.4, 0,
	0.8, -0.4, 0,
	-0.8 0.4, 0,
	0.8, -0.4, 0,
	-0.8, -0.4, 0	
	];
	
var colors = [
	1, 0, 0, 1,
	0, 1, 0, 1,
	0, 0, 1, 1,
	1, 0, 0, 1,
	0, 0, 1, 1, 
	1, 0, 1, 1
	];
```
- This defines two triangles, that form a quad (every three values in positions is a vertex, every nine values in positions defines a triangle with three vertices)
	- Note two vertices are repeated because they are shared in the quad

Allocating Data on GPU
```JS
var position_buffer = gl.createBuffer();  // create the buffer to store data

gl.bindBuffer(
	gl.ARRAY_BUFFER,
	position_buffer);  // bind the buffer

gl.bufferData(
	gl.ARRAY_BUFFER,
	new Float32Array(positions),
	gl.STATIC_DRAW);  // convert positions array to 32 bit floating point value array, and send it to the buffer we binded, STATIC_DRAW is for when we don't plan to modify the data (optimization), note array size hasn't been specified. This part does the memory allocation

var color_buffer = gl.createBuffer();

gl.bindBuffer(
	gl.ARRAY_BUFFER,
	color_buffer);

gl.bufferData(
	gl.ARRAY_BUFFER,
	new Float32Array(colors),
	gl.STATIC_DRAW);
```
- At any time, we can only have one bound buffer (when we bound color_buffer to ARRAY_BUFFER, we unbound position_buffer to ARRAY_BUFFER)




