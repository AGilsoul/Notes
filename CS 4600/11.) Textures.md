### Texture
- We will define it as an image that we put on the surface of a model
### Texture Mapping
- Map our object surface onto the texture space
- Need to know where each triangle lands on the texture space to find the value on the object
	- Map each vertex onto the texture space
- In texture space, bottom left is origin
- Right axis is u
- Left axis is v
- $\begin{bmatrix}x\\y\\z\end{bmatrix} \implies \begin{bmatrix}u\\v\end{bmatrix}$
- But we have to define this mapping! This is hard, with lots of manual labor and is a messy process, but typically how it is done
### GPU Pipeline
- Texture is used in the Fragment Shader
- Look at center coordinate of each fragment, and map that onto the texture space to find the value
- GPU uses barycentric coordinate stuff we talked about
- Once we map this point onto the texture space, we have to find its texture value which is also tricky, we do this with texture sampling
### Texture Sampling (Texture Filtering)
- For each point, we can find the closest point to it on the texture map and take its value
	- This results in a much lower quality image!
- We can also do a bilinear interpolation of the four closest points to take the value
	- Called Bilinear Filtering
### Bilinear Filtering
- Given four closest points to $\textbf{c}$: $\textbf{c}_0,\textbf{c}_1,\textbf{c}_2,\textbf{c}_3$
- ![[Pasted image 20241015001522.png]]
	- Or
- $\textbf{c}=(1-t)(1-s)\textbf{c}_0+(1-t)s\textbf{c}_1+t(1-s)\textbf{c}_2+ts\textbf{c}_3$
	- Note each coefficient for a point is the area of each rectangle opposing the point!
- This still isn't the best though, because there is discontinuities in the groups of points used as they move, since we only use the nearest square of points
- The easiest thing to do to improve quality is to use a higher resolution image for your texture!
- #### Bicubic Filtering
	- Looks at all texture values in the nearest 4x4 square of points
	- Allows for a smoother change in texture
- What if we move something far away from our camera though!
	- We get weird flickering as the camera moves
	- This is because an individual pixel moves over more of the texture the farther away it is when the camera moves
	- We use pre-filtering to get the average value of a texel, so that we don't have to constantly compute the averages of many texels when the texture is very far away
### Mipmaps
- Computed averages for different levels of resolution of a texture image
- ![[Pasted image 20241015003520.png]]
- Every region of four texels is converted into one texel at the next level
- Easier if the image resolution is a power of 2
- Use a mipmap to approximate the region a pixel will cover on the texture, and choose a mipmap level that matches the pixel size to the texel size on the mipmap. Then do bilinear interpolation
- If the pixel size is in between texel sizes on two levels, we can do a linear interpolation of the bilinear interpolation between the values from the bilinear interpolation of both levels based on the area of the pixel
- ![[Pasted image 20241015003954.png]]
- Called ***Trilinear Filtering
- This is definitely better than just bilinear filtering, but kind of blurry for stuff far away
### Anisotropic Filtering (with Mipmaps)
- Instead of trilinear filtering one time, do it multiple times to cover the region covered by the pixel
- ![[Pasted image 20241015004354.png]]\
- Very useful when we are viewing a surface texture at an angle, and minimizes blur
- This is expensive, however
### Textures (in general)
- Raster Images (1D, 2D, 3D, ...)
- Procedural Textures (some function)
- Alternative Structures
	- Ptex (Per-Face Textures)
		- Mapping done for each quad face, and is immediately implicitly defined for each face
	- Mesh Colors
		- Similar to Ptex, but define mesh colors at different levels on the quads/triangles



